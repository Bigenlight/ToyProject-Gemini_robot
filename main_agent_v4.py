import mujoco
import mujoco.viewer
import numpy as np
import time
import threading
import queue
import os
import sys
from google import genai
from google.genai import types
from PIL import Image

# ---------------------------------------------------------
# 1. ì„¤ì • ë° API í‚¤
# ---------------------------------------------------------
MODEL_NAME = "gemini-3-flash-preview"
SCENE_XML = "scene.xml"
TARGET_SITE_NAME = "gripper" 

try:
    key_path = os.path.join(os.path.dirname(os.getcwd()), "api_key.txt")
    with open(key_path, "r") as f:
        MY_API_KEY = f.readline().strip()
    print(f"ğŸ”‘ API Key ë¡œë“œ ì„±ê³µ: {key_path}")
except FileNotFoundError:
    print(f"âŒ [Error] API í‚¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    sys.exit(1)

# ì´ˆê¸° ìì„¸
HOME_QPOS = np.array([0, 0, 0, -1.5708, 0, 1.5708, 0.732, 0.04, 0.04])

# [New] ì†ë„ ì œí•œ (Rad/step) - ë¡œë´‡ì´ ë¯¸ì³ ë‚ ë›°ëŠ” ê²ƒ ë°©ì§€
MAX_JOINT_VELOCITY = 0.05 

# ë°”ë‹¥ ë³´ê¸° íšŒì „ í–‰ë ¬
FIXED_ROTATION = np.array([
    [1,  0,  0],
    [0, -1,  0],
    [0,  0, -1]
])

# ---------------------------------------------------------
# 2. Gemini ë‘ë‡Œ (ëª¨ë‹ˆí„°ë§ & ì •ë³´ ê°•í™”)
# ---------------------------------------------------------
class GeminiBrain(threading.Thread):
    def __init__(self, client, model_name, result_queue):
        super().__init__()
        self.client = client
        self.model_name = model_name
        self.result_queue = result_queue
        self.input_image = None
        self.current_ee_pos = None # í˜„ì¬ ì† ìœ„ì¹˜ ê¸°ì–µ
        self.is_thinking = False
        self.daemon = True 

    def think(self, image, current_pos):
        if self.is_thinking: return 
        self.input_image = image
        self.current_ee_pos = current_pos
        self.is_thinking = True
        self.start_processing()

    def start_processing(self):
        threading.Thread(target=self._api_call).start()

    def _api_call(self):
        start_time = time.time() # ì‹œê°„ ì¸¡ì • ì‹œì‘
        try:
            # í˜„ì¬ ìœ„ì¹˜ í¬ë§·íŒ…
            curr_str = f"[{self.current_ee_pos[0]:.2f}, {self.current_ee_pos[1]:.2f}, {self.current_ee_pos[2]:.2f}]" if self.current_ee_pos is not None else "Unknown"

            # [Updated Prompt] ê·¸ë¦¬ë“œ ì •ë³´ ë° í˜„ì¬ ìœ„ì¹˜ ì¶”ê°€
            prompt = f"""
            Look at the simulation screen.
            1. Identify the 'Green Sphere' (Current End-Effector) and the 'Red Cube' (Target).
            2. The 'Green Sphere' is currently at {curr_str}.
            3. Estimate the 3D position [x, y, z] of the Red Cube center relative to the robot base.
            
            [Visual Scale Info]
            - The floor has a grid pattern.
            - Blue squares are 0.2m x 0.2m.
            - White squares (composed of 4 blue ones) are 0.4m x 0.4m.
            
            [Constraint]
            - Robot base is at [0, 0, 0].
            - Table/Floor height is around z=0.0.
            
            Output ONLY the python list format e.g., [0.5, 0.1, 0.025].
            """
            
            config = types.GenerateContentConfig(
                safety_settings=[
                    types.SafetySetting(category="HARM_CATEGORY_HARASSMENT", threshold="BLOCK_NONE"),
                    types.SafetySetting(category="HARM_CATEGORY_HATE_SPEECH", threshold="BLOCK_NONE"),
                    types.SafetySetting(category="HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold="BLOCK_NONE"),
                    types.SafetySetting(category="HARM_CATEGORY_DANGEROUS_CONTENT", threshold="BLOCK_NONE"),
                ]
            )

            response = self.client.models.generate_content(
                model=self.model_name,
                contents=[prompt, self.input_image],
                config=config
            )
            
            if not response.text:
                return

            text = response.text.strip()
            start, end = text.find('['), text.find(']')
            
            if start != -1 and end != -1:
                coord_str = text[start:end+1]
                import ast
                target_pos = np.array(ast.literal_eval(coord_str))
                
                # ê²°ê³¼ íì— ë„£ê¸° (ì¢Œí‘œ, ì†Œìš”ì‹œê°„)
                duration = time.time() - start_time
                self.result_queue.put((target_pos, duration))
                
            else:
                print(f"\nâš ï¸ [Gemini] ì¢Œí‘œ íŒŒì‹± ì‹¤íŒ¨: {text}")

        except Exception as e:
            print(f"\nâŒ [Gemini Error] {e}")
        finally:
            self.is_thinking = False

# ---------------------------------------------------------
# 3. 6-DoF IK í•¨ìˆ˜
# ---------------------------------------------------------
def get_orientation_error(current_mat, target_mat):
    r_err_mat = target_mat @ current_mat.T
    quat_err = np.zeros(4)
    mujoco.mju_mat2Quat(quat_err, r_err_mat.flatten())
    if quat_err[0] < 0: quat_err = -quat_err
    rot_err = quat_err[1:] * 2.0
    return rot_err

def solve_ik(model, data, target_pos, target_rot, site_name):
    site_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_SITE, site_name)
    current_pos = data.site_xpos[site_id]
    current_mat = data.site_xmat[site_id].reshape(3, 3)

    # ì—ëŸ¬ ê³„ì‚°
    error_pos = target_pos - current_pos
    error_rot = get_orientation_error(current_mat, target_rot)
    error_full = np.hstack([error_pos, error_rot])
    
    # [ì•ˆì „ì¥ì¹˜ 1] IK íƒ€ê²Ÿì´ ë„ˆë¬´ ë©€ë©´ ì—ëŸ¬ ë²¡í„°ë¥¼ ì˜ë¼ëƒ„ (Clamping)
    # í•œ ë²ˆì— 5cm ì´ìƒ ê³„ì‚°í•˜ë ¤ í•˜ì§€ ë§ˆë¼.
    if np.linalg.norm(error_full) > 0.05:
        error_full = error_full / np.linalg.norm(error_full) * 0.05

    # Jacobian
    jacp = np.zeros((3, model.nv))
    jacr = np.zeros((3, model.nv))
    mujoco.mj_jacSite(model, data, jacp, jacr, site_id)
    J = np.vstack([jacp[:, :7], jacr[:, :7]]) 
    
    # Solve
    diag = 0.05 * np.eye(6)
    dq = J.T @ np.linalg.solve(J @ J.T + diag, error_full)
    
    return dq

# ---------------------------------------------------------
# 4. ë©”ì¸ ë£¨í”„
# ---------------------------------------------------------
def main():
    client = genai.Client(api_key=MY_API_KEY)
    model = mujoco.MjModel.from_xml_path(SCENE_XML)
    data = mujoco.MjData(model)
    renderer = mujoco.Renderer(model, height=480, width=640)

    # ì´ˆê¸°í™”
    data.qpos[:9] = HOME_QPOS
    data.ctrl[:] = HOME_QPOS[:8]
    data.ctrl[7] = 255 
    mujoco.mj_forward(model, data)

    brain_queue = queue.Queue()
    brain = GeminiBrain(client, MODEL_NAME, brain_queue)
    
    current_target_pos = None
    
    print("ğŸ¦¾ [System] ì•ˆì •í™” ì—ì´ì „íŠ¸ ì‹œì‘.")
    
    with mujoco.viewer.launch_passive(model, data) as viewer:
        last_think_time = 0
        last_print_time = 0 # ëª¨ë‹ˆí„°ë§ ì¶œë ¥ìš©
        
        while viewer.is_running():
            step_start = time.time()
            now = time.time()

            # ---------------------------------------
            # 1. ëª¨ë‹ˆí„°ë§ (1ì´ˆì— í•œ ë²ˆ ì¶œë ¥)
            # ---------------------------------------
            if now - last_print_time > 1.0:
                site_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_SITE, TARGET_SITE_NAME)
                curr = data.site_xpos[site_id]
                print(f"ğŸ“ [Robot] EE Pos: [{curr[0]:.3f}, {curr[1]:.3f}, {curr[2]:.3f}]")
                last_print_time = now

            # ---------------------------------------
            # 2. ë‡Œ ì—…ë°ì´íŠ¸ (ê²°ê³¼ ìˆ˜ì‹ )
            # ---------------------------------------
            if not brain_queue.empty():
                new_pos, duration = brain_queue.get()
                current_target_pos = new_pos 
                print(f"ğŸš€ [Gemini] íƒ€ê²Ÿ ìˆ˜ì‹ : {new_pos} (ì†Œìš”ì‹œê°„: {duration:.2f}s)")
            
            # ---------------------------------------
            # 3. ë‡Œ ìš”ì²­ (ì£¼ê¸°ì )
            # ---------------------------------------
            if not brain.is_thinking and (now - last_think_time > 4.0):
                print("ğŸ“¸ [Scan] Geminiì—ê²Œ ìš”ì²­ ì¤‘...")
                renderer.update_scene(data)
                pixels = renderer.render()
                img = Image.fromarray(pixels)
                
                # í˜„ì¬ ë¡œë´‡ ì† ìœ„ì¹˜ë„ ê°™ì´ ë³´ëƒ„ (í”„ë¡¬í”„íŠ¸ íŒíŠ¸ìš©)
                site_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_SITE, TARGET_SITE_NAME)
                curr_pos_copy = data.site_xpos[site_id].copy()
                
                brain.think(img, curr_pos_copy)
                last_think_time = now

            # ---------------------------------------
            # 4. ë™ì‘ ì œì–´ (í•µì‹¬ ìˆ˜ì •ë¨)
            # ---------------------------------------
            if current_target_pos is not None:
                # IKë¡œ í•„ìš”í•œ ê´€ì ˆ ì†ë„(dq) ê³„ì‚°
                dq = solve_ik(model, data, current_target_pos, FIXED_ROTATION, TARGET_SITE_NAME)
                
                # [ì•ˆì „ì¥ì¹˜ 2] ì†ë„ ì œí•œ (Clamp Velocity)
                # ê´€ì ˆì´ ë„ˆë¬´ ë¹¨ë¦¬ ëŒì§€ ì•Šë„ë¡ ìë¦„
                dq = np.clip(dq, -MAX_JOINT_VELOCITY, MAX_JOINT_VELOCITY)
                
                # [í•µì‹¬ ë³€ê²½] ì ë¶„ ëˆ„ì (target_qpos += dq) ëŒ€ì‹ , í˜„ì¬ ìƒíƒœ ê¸°ë°˜ ì—…ë°ì´íŠ¸
                # q_next = q_current + dq * gain
                # ì´ë ‡ê²Œ í•˜ë©´ ë¡œë´‡ì´ ë¬¼ë¦¬ì ìœ¼ë¡œ ëª» ë”°ë¼ê°€ë„ ëª©í‘œê°’ì´ ì € ë©€ë¦¬ ë„ë§ê°€ì§€ ì•ŠìŒ
                next_qpos = data.qpos[:7] + dq 
                
                # ì œì–´ ì…ë ¥
                data.ctrl[:7] = next_qpos
            else:
                # íƒ€ê²Ÿ ì—†ìœ¼ë©´ ì œìë¦¬ ìœ ì§€
                data.ctrl[:7] = data.qpos[:7]

            # ---------------------------------------
            # 5. ê·¸ë¦¬í¼ ì œì–´
            # ---------------------------------------
            if current_target_pos is not None:
                site_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_SITE, TARGET_SITE_NAME)
                dist = np.linalg.norm(data.site_xpos[site_id] - current_target_pos)
                if dist < 0.05: data.ctrl[7] = 0.0 
                else: data.ctrl[7] = 255.0

            # 6. ë¬¼ë¦¬ ìŠ¤í…
            mujoco.mj_step(model, data)
            viewer.sync()
            
            elapsed = time.time() - step_start
            if elapsed < model.opt.timestep:
                time.sleep(model.opt.timestep - elapsed)

if __name__ == "__main__":
    main()